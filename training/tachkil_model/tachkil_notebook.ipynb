{"cells":[{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T10:45:48.797242Z","iopub.status.busy":"2022-05-17T10:45:48.796692Z","iopub.status.idle":"2022-05-17T10:45:51.764438Z","shell.execute_reply":"2022-05-17T10:45:51.763488Z","shell.execute_reply.started":"2022-05-17T10:45:48.797189Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset\n","\n","import pandas as pd\n","import numpy as np\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from time import time\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T10:45:52.751196Z","iopub.status.busy":"2022-05-17T10:45:52.750881Z","iopub.status.idle":"2022-05-17T10:46:06.568056Z","shell.execute_reply":"2022-05-17T10:46:06.566703Z","shell.execute_reply.started":"2022-05-17T10:45:52.751163Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv('../datasets/Arabic_poem_reduced.csv').dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T10:46:06.570293Z","iopub.status.busy":"2022-05-17T10:46:06.570016Z","iopub.status.idle":"2022-05-17T10:46:06.591266Z","shell.execute_reply":"2022-05-17T10:46:06.590416Z","shell.execute_reply.started":"2022-05-17T10:46:06.570259Z"},"trusted":true},"outputs":[],"source":["vocab = [' ', '!', '\"', '(', ')', '*', ',', '-', '.', ':', '?', '_', '«', '»', '،', '؛', '؟', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', 'ٍ', '–', '…']\n","\n","vocab2token = { vocab[i]:i+1    for i in range(len(vocab)) }\n","token2vocab = { i+1:vocab[i]    for i in range(len(vocab)) }\n","\n","def sentence2tokens(s):\n","    return [vocab2token[c] if c in vocab else len(vocab) for c in s]\n","\n","def tokens2sentence(t):\n","    return [token2vocab[c] for c in t]\n","\n","special = ['َ', 'ُ', 'ِ', 'ً', 'ٌ', 'ٍ', 'َّ', 'ُّ', 'ِّ','ًّ', 'ٌّ', 'ٍّ', 'ْ','ّ']\n","sps_dict = {}\n","for i, c in enumerate(special):\n","    sps_dict[c] = i\n","    \n","def get_sentence_tachkil(sentence):\n","    \"\"\"\n","        Get the letters, tachkil of a sentence along with the tachkil ratio of the sentence\n","        Input:\n","            sentence (str)\n","        Output:\n","            S list(str): letter\n","            T list(str): tachkilat\n","    \"\"\"\n","\n","    sentence = list(sentence)\n","    \n","    T = []\n","    S = []\n","    \n","    cnt = 0\n","\n","    i, j = 0 ,1\n","    L = len(sentence)\n","\n","    while i < L - 1:\n","        if sentence[i] == ' ':\n","            S.append(' ')\n","            T.append(-1)\n","            i += 1\n","            j += 1\n","\n","        else:\n","            S.append(sentence[i])\n","            if sentence[j] not in special:\n","                T.append(-1)\n","                i += 1\n","                j += 1\n","            \n","            elif sentence[j] != 'ّ':\n","                T.append(sps_dict[sentence[j]])\n","                cnt += 1\n","                i += 2\n","                j += 2\n","            \n","            else: # sentence[j] = 'ّ'\n","                if  j == L-1 or sentence[j+1] not in special: \n","                    T.append(sps_dict['ّ'])\n","                    cnt += 1\n","                    i += 2\n","                    j += 2\n","                else:\n","                    try:\n","                        T.append(sps_dict['ّ' + sentence[j+1]])\n","                    except:\n","                        T.append(sps_dict['ّ'])\n","                    cnt += 1\n","                    i += 3\n","                    j += 3\n","                    \n","\n","    if i < L:\n","        if sentence[-1] in special:\n","            T.append(sps_dict[sentence[-1]])\n","            cnt += 1\n","        else:\n","            S.append(sentence[-1])\n","            T.append(-1)\n","\n","    return S, T, cnt / len(S)\n","\n","\n","def rebuild_sentence(S, T):\n","    res = ''\n","    for c, t in zip(S, T):\n","        if t == 14:\n","            res  += c\n","        else:\n","            res = res + c + special[t]\n","\n","    return res"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T10:46:06.592895Z","iopub.status.busy":"2022-05-17T10:46:06.592503Z","iopub.status.idle":"2022-05-17T10:47:04.630532Z","shell.execute_reply":"2022-05-17T10:47:04.628486Z","shell.execute_reply.started":"2022-05-17T10:46:06.592863Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0 1684668 0\n","100000 1684668 15891\n","200000 1684668 30383\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_29153/14537320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'الشطر الايمن'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'الشطر الايسر'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3384\u001b[0m                 \u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3385\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3386\u001b[0;31m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3387\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3388\u001b[0m             )\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4603\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4604\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# We only take the sentences that have a tachkil ratio that is superior than the threshold tshd=0.55\n","\n","sentence = []\n","tachkils = []\n","tshd = 0.55\n","\n","for i in range(len(data)):\n","\n","    if i % 100000 == 0:\n","        print(i, len(data), len(sentence))\n","\n","    line = data.iloc[i]\n","    right, left = line['الشطر الايمن'], line['الشطر الايسر']\n","    \n","    try:\n","        clean_r, tachkil_r, ratio_r  = get_sentence_tachkil(right)\n","        if ratio_r > tshd:\n","            sentence.append(clean_r)\n","            tachkils.append(tachkil_r)\n","    except:\n","        print('1', i)\n","        \n","    try:\n","        clean_l, tachkil_l, ratio_l  = get_sentence_tachkil(left)\n","        if ratio_l > tshd:\n","            sentence.append(clean_l)\n","            tachkils.append(tachkil_l)\n","    except:\n","        print('2', i)\n","    "]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.status.busy":"2022-05-17T10:47:04.631826Z","iopub.status.idle":"2022-05-17T10:47:04.632176Z","shell.execute_reply":"2022-05-17T10:47:04.632008Z","shell.execute_reply.started":"2022-05-17T10:47:04.631991Z"},"trusted":true},"outputs":[],"source":["filtered_dataset = pd.DataFrame()\n","filtered_dataset['source'] = sentence\n","filtered_dataset['target'] = tachkils"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.status.busy":"2022-05-17T10:47:04.633141Z","iopub.status.idle":"2022-05-17T10:47:04.633462Z","shell.execute_reply":"2022-05-17T10:47:04.633305Z","shell.execute_reply.started":"2022-05-17T10:47:04.633289Z"},"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","\n","    def __init__(self, data):\n","        self.data = data\n","        self.L = len(data)\n","\n","\n","    def __len__(self):\n","        return self.L\n","\n","    def __getitem__(self, id):\n","\n","        line = self.data.iloc[id]\n","        x_ = line['source']\n","        y = line['target']\n","\n","        x = sentence2tokens(x_)\n","\n","        x = torch.tensor(x, dtype=torch.int64)\n","        y = torch.tensor(y, dtype=torch.int64)\n","        \n","        y[y == -1] = 14\n","            \n","        return {\n","                'original':x_,\n","                'target':y,\n","                'input':x,\n","            }\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.status.busy":"2022-05-17T10:47:04.634708Z","iopub.status.idle":"2022-05-17T10:47:04.635042Z","shell.execute_reply":"2022-05-17T10:47:04.634898Z","shell.execute_reply.started":"2022-05-17T10:47:04.634882Z"},"trusted":true},"outputs":[],"source":["def collate_fn(batch, maxlen=50):\n","    inputs, targets = [], []\n","    \n","    for line in batch:\n","        inputs.append(line['input'])\n","        targets.append(line['target'])\n","\n","    \n","    if len(max(inputs, key=lambda x:len(x))) <= maxlen:\n","        T = inputs[0]\n","        inputs[0]  = nn.ConstantPad1d((0, maxlen - T.shape[0]), 0)(T)\n","        T = targets[0]\n","        targets[0] = nn.ConstantPad1d((0, maxlen - T.shape[0]), -1)(T)\n","        \n","    inputs    = pad_sequence(inputs,  padding_value=0  , batch_first=True)\n","    targets   = pad_sequence(targets, padding_value=-1 , batch_first=True)\n","    \n","    return inputs, targets"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.status.busy":"2022-05-17T10:47:04.636174Z","iopub.status.idle":"2022-05-17T10:47:04.636582Z","shell.execute_reply":"2022-05-17T10:47:04.636397Z","shell.execute_reply.started":"2022-05-17T10:47:04.636373Z"},"trusted":true},"outputs":[],"source":["def split_data(data, s=0.7):\n","    import random\n","    ids = list(range(len(data)))\n","    random.shuffle(ids)\n","    x = int(len(ids)*s)\n","    return data.iloc[ids[:x]], data.iloc[ids[x:]]"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.status.busy":"2022-05-17T10:47:04.638006Z","iopub.status.idle":"2022-05-17T10:47:04.63834Z","shell.execute_reply":"2022-05-17T10:47:04.638183Z","shell.execute_reply.started":"2022-05-17T10:47:04.638159Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'There are 24,126 samples for training, and 10,341 samples for validation testing'"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["train_data, val_data = split_data(filtered_dataset)\n","\n","train_dataset = MyDataset(train_data)\n","val_dataset   = MyDataset(val_data)\n","\n","f'There are {len(train_dataset) :,} samples for training, and {len(val_dataset) :,} samples for validation testing'"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-05-16T15:13:54.511289Z","iopub.status.busy":"2022-05-16T15:13:54.511052Z","iopub.status.idle":"2022-05-16T15:13:54.516286Z","shell.execute_reply":"2022-05-16T15:13:54.51534Z","shell.execute_reply.started":"2022-05-16T15:13:54.511256Z"},"trusted":true},"outputs":[],"source":["TRAIN_BATCH_SIZE = 128\n","\n","train_dataloader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=TRAIN_BATCH_SIZE,\n","    shuffle=True, \n","    collate_fn=collate_fn, \n","#     prefetch_factor=1, \n","#     num_workers=1\n","    )\n","\n","val_dataloader = DataLoader(\n","    dataset=val_dataset,\n","    batch_size=128,\n","    shuffle=True, \n","    collate_fn=collate_fn, \n","#     prefetch_factor=1, \n","#     num_workers=1\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["## Model:"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T10:47:09.907774Z","iopub.status.busy":"2022-05-17T10:47:09.907127Z","iopub.status.idle":"2022-05-17T10:47:09.924956Z","shell.execute_reply":"2022-05-17T10:47:09.923753Z","shell.execute_reply.started":"2022-05-17T10:47:09.907718Z"},"trusted":true},"outputs":[],"source":["class LstmModel(nn.Module):\n","    def __init__(\n","        self,\n","        emb_dim,\n","        vocab_size,\n","        output_size,\n","    ):\n","        super(LstmModel, self).__init__()\n","        self.vocab_size  = vocab_size\n","        self.output_size = output_size\n","\n","        self.embdding     = nn.Embedding(num_embeddings=vocab_size, embedding_dim=emb_dim, padding_idx=0)\n","        self.pos_embdding = nn.Embedding(num_embeddings=15, embedding_dim=emb_dim, padding_idx=0)\n","\n","        self.lstm_layer_1 = nn.LSTM(\n","            input_size=emb_dim,\n","            hidden_size=256,\n","            num_layers=1,\n","            bidirectional=True,\n","            batch_first=True,\n","        )\n","\n","        self.lstm_layer_2 = nn.LSTM(\n","            input_size=self.lstm_layer_1.hidden_size * 2,\n","            hidden_size=256,\n","            num_layers=1,\n","            bidirectional=True,\n","            batch_first=True,\n","        )\n","\n","        self.lstm_layer_3 = nn.LSTM(\n","            input_size=self.lstm_layer_2.hidden_size * 2,\n","            hidden_size=256,\n","            num_layers=1,\n","            bidirectional=True,\n","            batch_first=True,\n","        )\n","\n","\n","        self.fc1 = nn.Linear(self.lstm_layer_3.hidden_size * 2, 256)\n","        self.fc2 = nn.Linear(256, 256)\n","        self.fc3 = nn.Linear(256, output_size)\n","        \n","\n","        self.dropout1 = nn.Dropout(0.5)\n","        self.dropout2 = nn.Dropout(0.5)\n","\n","\n","    def forward(self, src):\n","\n","        emb     = self.embdding(src)\n","\n","        lstm_1_seq, (lstm_1_h, lstm1_c) = self.lstm_layer_1(emb)\n","        lstm_2_seq, (lstm_2_h, lstm2_c) = self.lstm_layer_2(lstm_1_seq)\n","        lstm_3_seq, (lstm_3_h, lstm3_c) = self.lstm_layer_3(lstm_2_seq)\n","\n","        out = self.dropout1(F.relu(self.fc1(lstm_3_seq)))\n","        out = self.dropout2(F.relu(self.fc2(out)))\n","        out = self.fc3(out)\n","\n","        return out"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.status.busy":"2022-05-17T10:47:04.641111Z","iopub.status.idle":"2022-05-17T10:47:04.641415Z","shell.execute_reply":"2022-05-17T10:47:04.641273Z","shell.execute_reply.started":"2022-05-17T10:47:04.641257Z"},"trusted":true},"outputs":[],"source":["def train_step(model, src, tgt, optimizer, scheduler, loss_fn, max_norm=0.9):\n","    model.train()\n","    model.zero_grad()\n","\n","    src = src.to(device)\n","\n","    out = model(src)\n","    \n","    out = out.reshape(-1,OUTPUT_SIZE)\n","    tgt = tgt.reshape(-1).to(device)\n","    loss = loss_fn(out, tgt)\n","\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n","    optimizer.step()\n","    if scheduler:\n","        scheduler.step()\n","\n","    return loss.item()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.status.busy":"2022-05-17T10:47:04.642544Z","iopub.status.idle":"2022-05-17T10:47:04.642893Z","shell.execute_reply":"2022-05-17T10:47:04.642706Z","shell.execute_reply.started":"2022-05-17T10:47:04.642689Z"},"trusted":true},"outputs":[],"source":["def eval_model(model, dataloader, loss_fn, log_steps = 5):\n","    model.eval()\n","    eval_loss = 0\n","    i = 0\n","    L_train_dataloader = len(dataloader)\n","    \n","    for src, tgt in dataloader:\n","        \n","        src = src.to(device)\n","\n","        out = model(src)\n","\n","        out = out.reshape(-1,OUTPUT_SIZE)\n","        tgt = tgt.reshape(-1).to(device)\n","        loss = loss_fn(out, tgt)\n","        eval_loss += loss.item()\n","\n","        i += 1\n","        if i % ( L_train_dataloader / log_steps) < 1:\n","            print(f'        EVAL STEP: {i} / {L_train_dataloader}')\n","\n","    return eval_loss / i\n","\n","\n","\n","\n","def calculate_accuracy(model, dataloader):\n","    model.eval()\n","\n","    with torch.no_grad():\n","        a, r = 0, 0\n","        j = 0\n","        for src, tgt in dataloader:\n","\n","            src = src.to(device)\n","\n","            out = model(src).detach().cpu()\n","\n","            out = out.reshape(-1,OUTPUT_SIZE)\n","            tgt = tgt.reshape(-1)\n","\n","            out = torch.argmax(out, dim=-1)\n","            \n","            out = out[tgt != -1]\n","            tgt = tgt[tgt != -1]\n","            \n","            a += len(tgt)\n","            r += sum(tgt == out).item()\n","            \n","            j += 1\n","            \n","            if j % (len(dataloader) // 5) == 0:\n","                print(f'ACC STEP {j}/{len(dataloader)}')\n","\n","    return (r / a)"]},{"cell_type":"markdown","metadata":{},"source":["# Training:"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T10:47:12.901877Z","iopub.status.busy":"2022-05-17T10:47:12.901589Z","iopub.status.idle":"2022-05-17T10:47:12.950132Z","shell.execute_reply":"2022-05-17T10:47:12.949493Z","shell.execute_reply.started":"2022-05-17T10:47:12.901846Z"},"trusted":true},"outputs":[],"source":["VOCAB_SIZE  = len(vocab)+1 # 0 is for the padding \n","OUTPUT_SIZE = len(special)+1 # +1 for the non tachkil\n","\n","model = LstmModel(\n","    256,\n","    VOCAB_SIZE, \n","    OUTPUT_SIZE).to(device)\n","\n","n_model = 3\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-16T15:13:58.239509Z","iopub.status.busy":"2022-05-16T15:13:58.239239Z","iopub.status.idle":"2022-05-16T15:37:11.80324Z","shell.execute_reply":"2022-05-16T15:37:11.802153Z","shell.execute_reply.started":"2022-05-16T15:13:58.239474Z"},"trusted":true},"outputs":[],"source":["EPOCH = 30\n","log_steps = 10\n","L_train_dataloader = len(train_dataloader)\n","losses = []\n","eval_losses = []\n","lrs = []\n","max_val_acc = 0\n","val_acc = 0\n","\n","src, tgt =  next(iter(train_dataloader))\n","\n","for epoch in range(0, EPOCH+1):\n","    print(f'EPOCH: {epoch} START TRAINING ... ----------------------------------------------------------------------')\n","    epoch_loss = 0\n","    steps_loss = 0\n","    i, j = 0, 0\n","    s_time = time()\n","    # for _  in train_dataloader:\n","    for src, tgt in train_dataloader:\n","        i, j = i+1, j+1\n","        loss = train_step(model, src, tgt, optimizer, None, loss_fn)\n","        losses.append(loss)\n","        epoch_loss += loss\n","        steps_loss += loss\n","        if i % ( L_train_dataloader / log_steps) < 1:\n","            lr = optimizer.param_groups[0]['lr']\n","            lrs.append(lr)\n","            print(f'EPOCH: {epoch}    STEP: {i} / {L_train_dataloader}   STEP LOSS: {steps_loss / j:.5f}   TIME: {time() - s_time:.4f}    LR: {lr:.6f}')\n","            s_time = time()\n","            j = 0\n","            steps_loss = 0\n","    \n","    print('EVALUATION :')\n","    \n","    if (epoch + 1) % 1 == 0:\n","        val_acc = calculate_accuracy(model, val_dataloader)\n","    print(f'EPOCH: {epoch}    TRAINING LOSS: {epoch_loss / i:.5f}   VAL ACC: {val_acc*100:.3f}')\n","\n","\n","    if val_acc > max_val_acc:\n","        print(f'SAVING BEST MODEL {n_model}')\n","        max_val_acc = val_acc\n","        torch.save(model.state_dict(), f'best_lstm_model_{str(n_model)}.pt')\n","\n","    print('----------------------------------------------------------------------------------------------------', end='\\n\\n')"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation:"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load('../../models/tachkil/tachkil_model.pt', map_location=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-16T15:37:11.804256Z","iopub.status.idle":"2022-05-16T15:37:11.805721Z","shell.execute_reply":"2022-05-16T15:37:11.805493Z","shell.execute_reply.started":"2022-05-16T15:37:11.805464Z"},"trusted":true},"outputs":[],"source":["model.eval()\n","\n","tgts = []\n","outs = []\n","\n","with torch.no_grad():\n","    j = 0\n","    for src, tgt in val_dataloader:\n","\n","        src = src.to(device)\n","\n","        out = model(src).detach().cpu()\n","        \n","\n","        out = out.reshape(-1,OUTPUT_SIZE)\n","        tgt = tgt.reshape(-1)\n","\n","        out = torch.argmax(out, dim=-1)\n","\n","        out = out[tgt != -1]\n","        tgt = tgt[tgt != -1]\n","        \n","        out = list(out)\n","        tgt = list(tgt)\n","        \n","        tgts += tgt\n","        outs += out\n","\n","        j += 1\n","\n","        if j % (len(val_dataloader) // 5) == 0:\n","            print(f'ACC STEP {j}/{len(val_dataloader)}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-16T15:37:11.807Z","iopub.status.idle":"2022-05-16T15:37:11.807646Z","shell.execute_reply":"2022-05-16T15:37:11.807438Z","shell.execute_reply.started":"2022-05-16T15:37:11.807413Z"},"trusted":true},"outputs":[],"source":["outs = [c.item() for c in outs]\n","tgts = [c.item() for c in tgts]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-16T15:37:11.808873Z","iopub.status.idle":"2022-05-16T15:37:11.809524Z","shell.execute_reply":"2022-05-16T15:37:11.809298Z","shell.execute_reply.started":"2022-05-16T15:37:11.809273Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n","\n","print(accuracy_score(tgts, outs))\n","\n","fig, ax = plt.subplots(figsize=(20,20))\n","ConfusionMatrixDisplay.from_predictions(tgts, outs, ax=ax, normalize='true')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T10:47:23.434984Z","iopub.status.busy":"2022-05-17T10:47:23.434665Z","iopub.status.idle":"2022-05-17T10:47:23.446194Z","shell.execute_reply":"2022-05-17T10:47:23.44536Z","shell.execute_reply.started":"2022-05-17T10:47:23.434955Z"},"trusted":true},"outputs":[],"source":["poem = \"\"\"قُم فَاِسقِنيها قَبلَ صَوتِ الحَمام\n","كَرمِيَّةً تَجمَعُ شَملَ الكِرام\n","صَهباءَ مِمّا عَتَّقَت بابِلٌ\n","مِزاجُها الأَريُ وَماءُ الغَمام\n","مِمّا أُدِيرَ الكَأسُ مِنها عَلى\n","كِسرى وَنُمرُوذَ بنِ كُوشِ بنِ حام\n","لَوِ اِحتَساها اِبنُ الزُبَيرِ اِغتَدى\n","أَكرَمَ مِن كَعبٍ وَأَوسِ بنِ لام\n","تَذهَبُ بِاليَأسِ وَتُدني المُنى\n","وَتَنشُرُ اللَهوَ وَتَطوي الغَرام\n","أَو ذاقَها المَنزُوفُ ضَرطاً لَما\n","هابَ اِبنَ ذي الجَدَّينِ يَومَ الزِحام\n","وَحَرِّكِ الأَوتارَ وَاِذكُر لَنا\n","أَيّامنا الغُرَّ بَدارِ السَلام\n","وَتِلكُمُ الغُزلانُ بَينَ المَها\n","تَمشي إِلى الشَطِّ فِئاماً فِئام\n","مِن كُلِّ أَظمى فاتِرٍ طَرفُهُ\n","تُروى بِمَرآهُ القُلوبُ الحِيام\"\"\".strip().split('\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-17T10:47:23.519026Z","iopub.status.busy":"2022-05-17T10:47:23.518392Z","iopub.status.idle":"2022-05-17T10:47:26.741686Z","shell.execute_reply":"2022-05-17T10:47:26.740903Z","shell.execute_reply.started":"2022-05-17T10:47:23.518971Z"},"trusted":true},"outputs":[],"source":["for line in poem:\n","    S, T, _ = get_sentence_tachkil(line)\n","    \n","    x = sentence2tokens(S)\n","    x = torch.tensor(x, dtype=torch.int64)\n","    L = len(x)\n","    x  = nn.ConstantPad1d((0, 50 - x.shape[0]), 0)(x)\n","    x = x.unsqueeze(0).to(device)\n","    \n","    out = model(x)\n","    out = torch.argmax(out, dim=-1)[0,:L].cpu()\n","    out = list(np.array(out))\n","    \n","    print(f'Predicted: {rebuild_sentence(S, out)}')\n","    print(f'Original : {line}')\n","    print()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
